import streamlit as st
import subprocess
import math
import os
import glob
import openai
from pydub import AudioSegment
from langchain_community.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import StrOutputParser


llm = ChatOpenAI(
    temperature=0.1,
)


@st.cache_data()
def extract_audio_from_video(video_path):
    audio_path = video_path.replace("mp4", "mp3")
    command = [
        "ffmpeg",
        "-y",
        "-i",
        video_path,
        "-vn",
        audio_path,
    ]
    subprocess.run(command)


@st.cache_data()  # ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì²­í¬ë¡œ ë‚˜ëˆ„ê¸°
def cut_audio_in_chunks(audio_path, chunk_size, chunks_folder):
    track = AudioSegment.from_mp3(audio_path)  # ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ
    chunk_length = chunk_size * 60 * 1000  # ì²­í¬ í¬ê¸°ë¥¼ ë°€ë¦¬ì´ˆë¡œ ë³€í™˜
    chunks = math.ceil(len(track) / chunk_length)
    if not os.path.exists(chunks_folder):  # ì²­í¬ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±
        os.makedirs(chunks_folder)
    for i in range(chunks):  # ê° ì²­í¬ë¥¼ ê°œë³„ íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°
        start_time = i * chunk_length
        end_time = (i + 1) * chunk_length
        chunk = track[start_time:end_time]
        chunk.export(f"{chunks_folder}/openai-devday_{i + 1:02d}.mp3", format="mp3")


has_transcript = os.path.exists("./.cache/openai-devday.txt")


@st.cache_data()  # í´ë” ë‚´ ëª¨ë“  ì²­í¬ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
def transcribe_chunks(chunk_folder, destination):
    if has_transcript:
        return
    files = glob.glob(f"{chunk_folder}/*.mp3")
    files.sort()
    final_transcription = ""
    for file in files:
        with open(file, "rb") as audio_file:
            transcription = openai.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
            )
            if hasattr(transcription, "text"):
                final_transcription += transcription.text
            else:
                print(f"Warning: No 'text' attribute in transcription for file {file}")
    with open(destination, "w", encoding="utf-8") as file:  # ê¸°ì¡´ íŒŒì¼ì— ë”í•¨
        file.write(final_transcription)


# # ê²½ë¡œ ì„¤ì •
# audio_path = "./openai-devday.mp3"
# chunks_folder = "./.cache/chunks"
# chunk_size = 10  # ì²­í¬ í¬ê¸° (ë¶„ ë‹¨ìœ„)


st.set_page_config(
    page_title="Site",
    page_icon="ğŸ“ƒ",
)

st.title("MeetingGPT")

st.markdown(
    """
    ## Welcome to MeetingGPT

    Experience seamless transcription and summary of your meetings with MeetingGPT. 
    
    Upload your video, and we'll provide a detailed transcript, a concise summary, and a chatbot to assist with any queries you might have.

    Get started by uploading a video file via the sidebar.
    """
)


with st.sidebar:
    video = st.file_uploader(
        "Video",
        type=["mp4", "avi", "mkv", "mov"],
    )
if video:
    with st.status("Loading video...") as status:
        video_content = video.read()
        video_path = f"./.cache/{video.name}"
        audio_path = video_path.replace("mp4", "mp3")
        transcription_path = video_path.replace("mp4", "txt")
        with open(video_path, "wb") as f:
            f.write(video_content)

        status.update(label="Extracting audio...")
        extract_audio_from_video(video_path)

        status.update(label="Cutting audio segments...")
        cut_audio_in_chunks(audio_path, 10, "./.cache/chunks")

        status.update(label="Transcribing audio...")
        transcribe_chunks("./.cache/chunks", transcription_path)

    transcription_tab, summary_tab, qa_tab = st.tabs(
        [
            "Transcript",
            "Summary",
            "Q&A",
        ]
    )

    with transcription_tab:
        with open(transcription_path, "r", encoding="utf-8") as file:
            st.write(file.read())

    with summary_tab:
        start = st.button("Generate Summary")

        if start:

            loader = TextLoader(transcription_path)
            splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
                chunk_size=800,
                chunk_overlap=100,
            )
            docs = loader.load_and_split(text_splitter=splitter)

            first_summary_prompt = ChatPromptTemplate.from_template(
                """
            Write a concise summary of the following:
            "{text}"
            CONCISE SUMMARY:   

            """
            )

            first_summary_chain = first_summary_prompt | llm | StrOutputParser()
            summary = first_summary_chain.invoke({"text": docs[0].page_content})

            refine_prompt = ChatPromptTemplate.from_template(
                """
                Your job is to produce a final summary.
                We have provided an existing summary up to a certain point: 
                {existing_summary}
                We have the opportunity to refind the existing summary
                (only if needed) with some more context below.
                -----------------------------------------------
                {text}
                -----------------------------------------------
                Given the new context, refind he original summary. 
                If the context isn't useful, RETURN the original summary.

                """
            )

            refine_chain = refine_prompt | llm | StrOutputParser()

            for doc in docs[1:]:
                summary = refine_chain.invoke(
                    {
                        "existing_summary": summary,
                        "context": doc.page_content,
                    }
                )
            st.write(summary)
